{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Final Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nom Etudiant :  SARR**  \n",
    "\n",
    "**Prenom Etudiant: Abdoulaye**  \n",
    "\n",
    "**Classe : BIG DATA**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Ce projet consiste à utiliser Apache Spark pour faire l'analyse et le traitement des données de **[San Francisco Fire Department Calls ](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)** afin de fournir quelques KPI (*Key Performance Indicator*). Le **SF Fire Dataset** comprend les réponses aux appels de toutes les unités d'incendie. Chaque enregistrement comprend le numéro d'appel, le numéro d'incident, l'adresse, l'identifiant de l'unité, le type d'appel et la disposition. Tous les intervalles de temps pertinents sont également inclus. Étant donné que ce Dataset est basé sur les réponses et que la plupart des appels impliquent plusieurs unités, ainsi il existe plusieurs enregistrements pour chaque numéro d'appel. Les adresses sont associées à un numéro de bloc, à une intersection ou à une boîte d'appel, et non à une adresse spécifique.\n",
    "\n",
    "**Plus de details sur la description des données cliquer sur ce [lien](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail à faire.\n",
    "L'objectif de ce projet est de comprendre le **SF Fire Dataset** afin de bien répondre aux questions en utilisant les codes Spark/Scala adéquates.\n",
    "\n",
    "- Créer un repos git (public ou privé) et partager le repos avec mon mail (limahin10@gmail.com)\n",
    "- Ecrire un code lisible et bien indenté \n",
    "- N'oublier pas de mettre en commentaire la justification de vos réponses sur les cellules Markdown. \n",
    "\n",
    "\n",
    "## Note:\n",
    "- Le projet est personnel, c'est-à-dire chaque notebook ne concerne qu'un seul étudiant. \n",
    "- Deadline : **Jeudi 10 janvier 2021** (Aucune de dérogation ne sera acceptée)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des packages Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://abdoulayesarr-HP-EliteBook-8460p:4040\n",
       "SparkContext available as 'sc' (version = 3.0.1, master = local[*], app id = local-1610225619210)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.sql.functions._\n",
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._ \n",
    "import org.apache.spark.sql.functions._ \n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons jeter un coup d'oeil sur la structure des données avant de définir un schéma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CallNumber,UnitID,IncidentNumber,CallType,CallDate,WatchDate,CallFinalDisposition,AvailableDtTm,Address,City,Zipcode,Battalion,StationArea,Box,OriginalPriority,Priority,FinalPriority,ALSUnit,CallTypeGroup,NumAlarms,UnitType,UnitSequenceInCallDispatch,FirePreventionDistrict,SupervisorDistrict,Neighborhood,Location,RowID,Delay\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!head -1 \"datasets/sf-fire/sf-fire-calls.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vu que la taille de ces données est énormes, inferer le schema pour un très grande volumes de données s'avère un peu couteux. Nous allons ainsi définir un schema pour le Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fireSchema: org.apache.spark.sql.types.StructType = StructType(StructField(CallNumber,IntegerType,true), StructField(UnitID,StringType,true), StructField(IncidentNumber,IntegerType,true), StructField(CallType,StringType,true), StructField(CallDate,StringType,true), StructField(WatchDate,StringType,true), StructField(CallFinalDisposition,StringType,true), StructField(AvailableDtTm,StringType,true), StructField(Address,StringType,true), StructField(City,StringType,true), StructField(Zipcode,IntegerType,true), StructField(Battalion,StringType,true), StructField(StationArea,StringType,true), StructField(Box,StringType,true), StructField(OriginalPriority,StringType,true), StructField(Priority,StringType,true), StructField(FinalPriority,IntegerType,true), StructField(ALSUnit,BooleanType,true)...\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fireSchema = StructType(Array(StructField(\"CallNumber\", IntegerType, true),\n",
    "  StructField(\"UnitID\", StringType, true),\n",
    "  StructField(\"IncidentNumber\", IntegerType, true),\n",
    "  StructField(\"CallType\", StringType, true),                  \n",
    "  StructField(\"CallDate\", StringType, true),      \n",
    "  StructField(\"WatchDate\", StringType, true),\n",
    "  StructField(\"CallFinalDisposition\", StringType, true),\n",
    "  StructField(\"AvailableDtTm\", StringType, true),\n",
    "  StructField(\"Address\", StringType, true),       \n",
    "  StructField(\"City\", StringType, true),       \n",
    "  StructField(\"Zipcode\", IntegerType, true),       \n",
    "  StructField(\"Battalion\", StringType, true),                 \n",
    "  StructField(\"StationArea\", StringType, true),       \n",
    "  StructField(\"Box\", StringType, true),       \n",
    "  StructField(\"OriginalPriority\", StringType, true),       \n",
    "  StructField(\"Priority\", StringType, true),       \n",
    "  StructField(\"FinalPriority\", IntegerType, true),       \n",
    "  StructField(\"ALSUnit\", BooleanType, true),       \n",
    "  StructField(\"CallTypeGroup\", StringType, true),\n",
    "  StructField(\"NumAlarms\", IntegerType, true),\n",
    "  StructField(\"UnitType\", StringType, true),\n",
    "  StructField(\"UnitSequenceInCallDispatch\", IntegerType, true),\n",
    "  StructField(\"FirePreventionDistrict\", StringType, true),\n",
    "  StructField(\"SupervisorDistrict\", StringType, true),\n",
    "  StructField(\"Neighborhood\", StringType, true),\n",
    "  StructField(\"Location\", StringType, true),\n",
    "  StructField(\"RowID\", StringType, true),\n",
    "  StructField(\"Delay\", FloatType, true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sfFireFile: String = datasets/sf-fire/sf-fire-calls.csv\n",
       "fireDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sfFireFile = \"datasets/sf-fire/sf-fire-calls.csv\"\n",
    "val fireDF = spark\n",
    "  .read\n",
    "  .schema(fireSchema)\n",
    "  .option(\"header\", \"true\")\n",
    "  .csv(sfFireFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|Zipcode| Box|\n",
      "+-------+----+\n",
      "|  94109|3362|\n",
      "|  94124|6495|\n",
      "+-------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireDF.select(\"Zipcode\",\"Box\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons mettre en cache le Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: fireDF.type = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fireDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Long = 175296\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fireDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         null|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         null|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         null|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         null|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         null|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrage des d'appels de type \"Medical Incident\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fewFireDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [IncidentNumber: int, AvailableDtTm: string ... 1 more field]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fewFireDF = fireDF\n",
    "  .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\") \n",
    "  .where($\"CallType\" =!= \"Medical Incident\")\n",
    "\n",
    "fewFireDF.show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "**Combien de types d'appels distincts ont été passés ?**  \n",
    "Pour être sûr, il ne faut pas compter les valeurs «nulles» dans la colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rst: Long = 29\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rst = fewFireDF.select($\"CallType\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quels types d'appels différents ont été passés au service d'incendie?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|      CallType|\n",
      "+--------------+\n",
      "|   Marine Fire|\n",
      "|  Vehicle Fire|\n",
      "|  Outside Fire|\n",
      "|Structure Fire|\n",
      "+--------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "result: Unit = ()\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val result = fewFireDF.\n",
    "             select($\"CallType\").\n",
    "             filter($\"CallType\".contains(\"Fire\")).distinct().\n",
    "             show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "**Trouver toutes les réponses ou les délais sont supérieurs à 5 minutes?**\n",
    "\n",
    "*Indication\n",
    "1. Renommer la colonne Delay -> ReponseDelayedinMins\n",
    "2. Retourner un nouveau DataFrame\n",
    "3. Afficher tous les appels où le temps de réponse à un site d'incendie a eu lieu après un retard de plus de 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+--------------------+--------------------+\n",
      "|ResponseDelayedinMins|       AvailableDtTm|            CallType|        Neighborhood|\n",
      "+---------------------+--------------------+--------------------+--------------------+\n",
      "|                 5.35|01/11/2002 04:34:...|    Medical Incident|  West of Twin Peaks|\n",
      "|                 6.25|01/12/2002 01:23:...|    Medical Incident|        Russian Hill|\n",
      "|                  5.2|01/13/2002 01:51:...|    Medical Incident|          Tenderloin|\n",
      "|                  5.6|01/14/2002 08:16:...|Citizen Assist / ...|     Sunset/Parkside|\n",
      "|                 7.25|01/14/2002 12:27:...|    Medical Incident|Financial Distric...|\n",
      "|            11.916667|01/15/2002 06:53:...|    Medical Incident|     South of Market|\n",
      "|             5.116667|01/15/2002 03:18:...|    Medical Incident| Castro/Upper Market|\n",
      "|             8.633333|01/15/2002 03:55:...|    Medical Incident|         North Beach|\n",
      "|             95.28333|01/15/2002 07:49:...|    Medical Incident|         North Beach|\n",
      "|                 5.45|01/15/2002 08:17:...|    Medical Incident|     South of Market|\n",
      "+---------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "newFireDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n",
       "rst: Unit = ()\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Reponse 3\n",
    "val newFireDF = fireDF.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")\n",
    "val rst = newFireDF\n",
    "         .select(\"ResponseDelayedinMins\", \"AvailableDtTm\",\"CallType\",\"Neighborhood\")\n",
    "         .filter($\"ResponseDelayedinMins\" > 5)\n",
    "         .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations des dates\n",
    "Maintenant nous allons d'abord:\n",
    "1. Transformer les dates de type String en Spark Timestamp afin que nous puissions effectuer des requêtes basées sur la date plus tard\n",
    "2. Retourner le Dataframe transformée\n",
    "3. Mettre en cache le nouveau DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fireTSDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n",
       "res6: fireTSDF.type = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fireTSDF = newFireDF\n",
    "  .withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\")).drop(\"CallDate\") \n",
    "  .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\")).drop(\"WatchDate\") \n",
    "  .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"), \"MM/dd/yyyy hh:mm:ss a\")).drop(\"AvailableDtTm\")\n",
    "\n",
    "fireTSDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|        OnWatchDate|      AvailableDtTS|       IncidentDate|\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-10 00:00:00|2002-01-11 01:51:44|2002-01-11 00:00:00|\n",
      "|2002-01-10 00:00:00|2002-01-11 03:01:18|2002-01-11 00:00:00|\n",
      "|2002-01-10 00:00:00|2002-01-11 02:39:50|2002-01-11 00:00:00|\n",
      "|2002-01-10 00:00:00|2002-01-11 04:16:46|2002-01-11 00:00:00|\n",
      "|2002-01-10 00:00:00|2002-01-11 06:01:58|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 08:03:26|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 09:46:44|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 09:58:53|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 12:06:57|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 13:08:40|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 15:31:02|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 14:59:04|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 16:22:49|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 16:18:33|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 16:09:08|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 16:09:08|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 16:09:08|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 16:34:23|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 16:51:31|2002-01-11 00:00:00|\n",
      "|2002-01-11 00:00:00|2002-01-11 16:51:12|2002-01-11 00:00:00|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireTSDF.select($\"OnWatchDate\",$\"AvailableDtTS\",$\"IncidentDate\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "**Quels sont les types d'appels les plus courants?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            CallType| count|\n",
      "+--------------------+------+\n",
      "|    Medical Incident|113794|\n",
      "|      Structure Fire| 23319|\n",
      "|              Alarms| 19406|\n",
      "|   Traffic Collision|  7013|\n",
      "|Citizen Assist / ...|  2524|\n",
      "|               Other|  2166|\n",
      "|        Outside Fire|  2094|\n",
      "|        Vehicle Fire|   854|\n",
      "|Gas Leak (Natural...|   764|\n",
      "|        Water Rescue|   755|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "appelCourant: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [CallType: string, count: bigint]\n"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 4\n",
    "val appelCourant = fireTSDF.select(\"CallType\").\n",
    "                  groupBy(\"CallType\").count().\n",
    "                  orderBy(desc(\"count\"))\n",
    "//affichons les dix types d'appel les plus courants\n",
    "appelCourant.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la reponse prouve que Medical Incident est largement plus courant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5-a\n",
    "**Quels sont boites postaux rencontrés dans les appels les plus courants?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+-----+\n",
      "|        CallType| Box|count|\n",
      "+----------------+----+-----+\n",
      "|Medical Incident|2251| 1544|\n",
      "|Medical Incident|1453| 1491|\n",
      "|Medical Incident|1461| 1205|\n",
      "|Medical Incident|5236| 1015|\n",
      "|Medical Incident|1545|  933|\n",
      "|Medical Incident|2252|  913|\n",
      "|Medical Incident|2248|  873|\n",
      "|Medical Incident|1365|  822|\n",
      "|Medical Incident|1546|  818|\n",
      "|Medical Incident|2242|  816|\n",
      "+----------------+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "appelCourant: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [CallType: string, Box: string ... 1 more field]\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 5-a\n",
    "val appelCourant = fireTSDF.//select(\"CallType\").\n",
    "                  groupBy($\"CallType\",$\"Box\").count().\n",
    "                  orderBy(desc(\"count\"))\n",
    "//affichons les 10 Box les plus courants\n",
    "appelCourant.show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5-b\n",
    "**Quels sont les quartiers de San Francisco dont les codes postaux sont 94102 et 94103?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Reponse 5-b\n",
    "val fewFireDF = fireDF.select(\"Neighborhood\", \"ZipCode\").\n",
    "                where($\"ZipCode\" === 94102 || $\"ZipCode\" === 94103).\n",
    "                distinct()\n",
    "fewFireDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "**Determiner le nombre total d'appels, ainsi que la moyenne, le minimum et le maximum du temps de réponse des appels?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|            Delay|\n",
      "+-------+-----------------+\n",
      "|  count|           175296|\n",
      "|   mean|3.892364154521585|\n",
      "| stddev|9.378286226254206|\n",
      "|    min|      0.016666668|\n",
      "|    max|          1844.55|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Reponse 6\n",
    "// on utilise la fonction describe pour voir les statistiques sur les temps de reponses\n",
    "fireDF.select(\"Delay\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7-a\n",
    "**Combien d'années distinctes trouve t-on dans ce Dataset?**  \n",
    "Dans ce dataset nous avons des données comprises entre 2000-2018. Vous pouvez utilisez la fonction Spark `year()` pour les dates en Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### affichons les années distincts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|year(IncidentDate)|\n",
      "+------------------+\n",
      "|              2003|\n",
      "|              2007|\n",
      "|              2018|\n",
      "|              2015|\n",
      "|              2006|\n",
      "|              2013|\n",
      "|              2014|\n",
      "|              2004|\n",
      "|              2012|\n",
      "|              2009|\n",
      "|              2016|\n",
      "|              2001|\n",
      "|              2005|\n",
      "|              2000|\n",
      "|              2010|\n",
      "|              2011|\n",
      "|              2008|\n",
      "|              2017|\n",
      "|              2002|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "annees: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [year(IncidentDate): int]\n"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val annees = fireTSDF.select(year($\"IncidentDate\")).distinct\n",
    "annees.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Maintenant on calcule le nombre d'annees distinctes avec la fonction count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le nombre d'années distinctes est: 19"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nbrDateDistinct: Long = 19\n"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val nbrDateDistinct = annees.count()\n",
    "print(s\"le nombre d'années distinctes est: $nbrDateDistinct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7-b\n",
    "**Quelle semaine de l'année 2018 a eu le plus d'appels d'incendie?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupérons les enregistrement 2018 et leurs semaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|date|weekofyear|\n",
      "+----+----------+\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "|2018|         3|\n",
      "+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "enreg2018AndWeek: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [date: int, weekofyear: int]\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 7-b\n",
    "val enreg2018AndWeek = fireTSDF.select(year($\"IncidentDate\").as(\"date\"),\n",
    "                weekofyear(col(\"IncidentDate\")).as(\"weekofyear\")).\n",
    "                filter($\"date\"===\"2018\")\n",
    "enreg2018AndWeek.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### groupons les enregistrement par les differentes semaine avec groupby-> count-> orderby\n",
    "   afin de recuperer les enregistrements des semaines les plus courant\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|weekofyear|count|\n",
      "+----------+-----+\n",
      "|        22|  259|\n",
      "|        40|  255|\n",
      "|        43|  250|\n",
      "|        25|  249|\n",
      "|         1|  246|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "groupeByWeek: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [weekofyear: int, count: bigint]\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val groupeByWeek  = enreg2018AndWeek.groupBy($\"weekofyear\").\n",
    "            count().orderBy(desc(\"count\"))\n",
    "groupeByWeek.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### on voit clairement que la semaine 22 à plus d'appels donc on recupere cette premiere enregistrement avec la fonction take et map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la semaine 22 a plus d'appel avec: 259   enregistrements\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "res13: Array[Unit] = Array(())\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupeByWeek.take(1)\n",
    ".map(a => println(s\"la semaine ${a(0)} a plus d'appel avec: ${a(1)}   enregistrements\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "**Quels sont les quartiers de San Francisco qui ont connu le pire temps de réponse en 2018?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupérons les enrégistrements de 2018, les quartiers et les délais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+--------------------+\n",
      "|date|ResponseDelayedinMins|        Neighborhood|\n",
      "+----+---------------------+--------------------+\n",
      "|2018|            2.8833334|    Presidio Heights|\n",
      "|2018|            6.3333335|         Mission Bay|\n",
      "|2018|                 2.65|           Chinatown|\n",
      "|2018|            3.5333333|Financial Distric...|\n",
      "|2018|                  1.1|          Tenderloin|\n",
      "|2018|                 4.05|Bayview Hunters P...|\n",
      "|2018|            2.5666666|      Inner Richmond|\n",
      "|2018|                  1.4|        Inner Sunset|\n",
      "|2018|            2.6666667|     Sunset/Parkside|\n",
      "|2018|            1.7666667|     South of Market|\n",
      "+----+---------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "enreg2018: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [date: int, ResponseDelayedinMins: float ... 1 more field]\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val enreg2018 = fireTSDF.select(year($\"IncidentDate\").\n",
    "                as(\"date\"),$\"ResponseDelayedinMins\",$\"Neighborhood\").\n",
    "                filter($\"date\"===\"2018\")\n",
    "enreg2018.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " on regroupe les enrégistrements par quartier puis on fait la sommes totales de leurs délai qui représente le temps de réponse grace aux fonction groupby agg sum et orderBy(pour trier par ordre decroissant)\n",
    " et on recupere les 10 quartiers ou il y a plus de temps de réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|        Neighborhood|       delai_total|\n",
      "+--------------------+------------------+\n",
      "|          Tenderloin| 5713.416682377458|\n",
      "|     South of Market| 4019.916673846543|\n",
      "|Financial Distric...|3353.6333242356777|\n",
      "|             Mission|3150.3333284556866|\n",
      "|Bayview Hunters P...|2411.9333442747593|\n",
      "|     Sunset/Parkside|1240.1333360522985|\n",
      "|           Chinatown|1182.3499933183193|\n",
      "|    Western Addition|1156.0833313167095|\n",
      "|            Nob Hill|1120.9999947845936|\n",
      "|        Hayes Valley| 980.7833325713873|\n",
      "+--------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neighborhood: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Neighborhood: string, delai_total: double]\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 8\n",
    "val neighborhood = enreg2018\n",
    "         .groupBy($\"Neighborhood\")\n",
    "         .agg(sum($\"ResponseDelayedinMins\").as(\"delai_total\"))\n",
    "         .orderBy(desc(\"delai_total\"))\n",
    "\n",
    "neighborhood.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "**Comment stocker les données du Dataframe sous format de fichiers Parquet?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Reponse 9\n",
    "fewFireDF.write.parquet(\"fewFireDF.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "**Comment relire les données stockée en format Parquet?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Reponse 10\n",
    "spark.read.parquet(\"fewFireDF.parquet\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
